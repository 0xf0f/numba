//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Fri Sep 28 18:17:15 2012 (1348874235)
// Cuda compilation tools, release 5.0, V0.2.1221
//

.version 3.1
.target sm_20
.address_size 32

	.file	1 "/tmp/tmpxft_00004986_00000000-9_cupow.cpp3.i"
	.file	2 "/Developer/NVIDIA/CUDA-5.0/bin//../include/math_functions.h"
	.file	3 "/Users/sklam/dev/numbapro/cuda_toolkit/ptx/cupow.cu"
	.file	4 "/Developer/NVIDIA/CUDA-5.0/nvvm/ci_include.h"
	.file	5 "/Developer/NVIDIA/CUDA-5.0/bin//../include/math_functions_dbl_ptx3.h"

.visible .func  (.param .b32 func_retval0) _Z7pow_f32ff(
	.param .b32 _Z7pow_f32ff_param_0,
	.param .b32 _Z7pow_f32ff_param_1
)
{
	.reg .pred 	%p<30>;
	.reg .f32 	%f<122>;
	.reg .s32 	%r<28>;


	ld.param.f32 	%f118, [_Z7pow_f32ff_param_0];
	ld.param.f32 	%f26, [_Z7pow_f32ff_param_1];
	setp.eq.f32 	%p1, %f118, 0f3F800000;
	mov.f32 	%f121, 0f3F800000;
	setp.eq.f32 	%p2, %f26, 0f00000000;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB0_25;

	abs.f32 	%f1, %f118;
	mov.u32 	%r1, 2139095040;
	mov.b32 	%f2, %r1;
	setp.gtu.f32 	%p4, %f1, %f2;
	@%p4 bra 	BB0_24;

	abs.f32 	%f3, %f26;
	setp.gtu.f32 	%p5, %f3, %f2;
	@%p5 bra 	BB0_24;

	setp.eq.f32 	%p6, %f2, %f118;
	@%p6 bra 	BB0_23;

	setp.eq.f32 	%p7, %f3, %f2;
	@%p7 bra 	BB0_19;

	mul.f32 	%f28, %f26, 0f3F000000;
	cvt.rzi.f32.f32 	%f29, %f28;
	fma.rn.f32 	%f30, %f29, 0fC0000000, %f26;
	abs.f32 	%f4, %f30;
	setp.eq.f32 	%p8, %f118, 0f00000000;
	@%p8 bra 	BB0_16;

	neg.f32 	%f31, %f2;
	setp.eq.f32 	%p9, %f118, %f31;
	@%p9 bra 	BB0_13;

	setp.geu.f32 	%p10, %f118, 0f00000000;
	@%p10 bra 	BB0_9;

	cvt.rzi.f32.f32 	%f32, %f26;
	setp.neu.f32 	%p11, %f32, %f26;
	@%p11 bra 	BB0_12;

BB0_9:
	mov.b32 	%r2, %f1;
	shr.u32 	%r3, %r2, 23;
	and.b32  	%r4, %r3, 255;
	setp.eq.s32 	%p12, %r4, 0;
	mul.f32 	%f33, %f1, 0f4B800000;
	mov.b32 	%r5, %f33;
	shr.u32 	%r6, %r5, 23;
	and.b32  	%r7, %r6, 255;
	add.s32 	%r8, %r7, -24;
	selp.f32 	%f34, %f33, %f1, %p12;
	selp.b32 	%r9, %r8, %r4, %p12;
	mov.b32 	%r10, %f34;
	and.b32  	%r11, %r10, -2139095041;
	or.b32  	%r12, %r11, 1065353216;
	mov.b32 	%f35, %r12;
	setp.gt.f32 	%p13, %f35, 0f3FB504F3;
	mul.f32 	%f36, %f35, 0f3F000000;
	selp.b32 	%r13, -126, -127, %p13;
	add.s32 	%r14, %r9, %r13;
	selp.f32 	%f37, %f36, %f35, %p13;
	add.f32 	%f38, %f37, 0fBF800000;
	add.f32 	%f39, %f37, 0f3F800000;
	rcp.rn.f32 	%f40, %f39;
	add.f32 	%f41, %f38, %f38;
	mul.f32 	%f42, %f41, %f40;
	mul.f32 	%f43, %f42, %f42;
	mov.f32 	%f44, 0f3C4CAF63;
	mov.f32 	%f45, 0f3B18F0FE;
	fma.rn.f32 	%f46, %f45, %f43, %f44;
	mov.f32 	%f47, 0f3DAAAABD;
	fma.rn.f32 	%f48, %f46, %f43, %f47;
	mul.rn.f32 	%f49, %f48, %f43;
	mul.rn.f32 	%f50, %f49, %f42;
	mov.b32 	%r15, %f42;
	and.b32  	%r16, %r15, -4096;
	mov.b32 	%f51, %r16;
	mov.b32 	%r17, %f38;
	and.b32  	%r18, %r17, -4096;
	mov.b32 	%f52, %r18;
	sub.f32 	%f53, %f38, %f51;
	add.f32 	%f54, %f53, %f53;
	sub.f32 	%f55, %f38, %f52;
	neg.f32 	%f56, %f51;
	fma.rn.f32 	%f57, %f56, %f52, %f54;
	fma.rn.f32 	%f58, %f56, %f55, %f57;
	mul.rn.f32 	%f59, %f40, %f58;
	add.f32 	%f60, %f51, %f59;
	sub.f32 	%f61, %f60, %f51;
	sub.f32 	%f62, %f59, %f61;
	add.f32 	%f63, %f60, %f50;
	sub.f32 	%f64, %f60, %f63;
	add.f32 	%f65, %f64, %f50;
	add.f32 	%f66, %f65, %f62;
	add.f32 	%f67, %f63, %f66;
	sub.f32 	%f68, %f63, %f67;
	add.f32 	%f69, %f68, %f66;
	cvt.rn.f32.s32 	%f70, %r14;
	mov.f32 	%f71, 0f3F317200;
	mul.rn.f32 	%f72, %f70, %f71;
	mov.f32 	%f73, 0f35BFBE8E;
	mul.rn.f32 	%f74, %f70, %f73;
	add.f32 	%f75, %f72, %f67;
	sub.f32 	%f76, %f72, %f75;
	add.f32 	%f77, %f76, %f67;
	add.f32 	%f78, %f77, %f69;
	add.f32 	%f79, %f78, %f74;
	add.f32 	%f80, %f75, %f79;
	sub.f32 	%f81, %f75, %f80;
	add.f32 	%f82, %f81, %f79;
	mul.f32 	%f83, %f26, 0f39000000;
	setp.gt.f32 	%p14, %f3, 0f77F684DF;
	selp.f32 	%f84, %f83, %f26, %p14;
	mul.rn.f32 	%f85, %f84, %f80;
	neg.f32 	%f86, %f85;
	fma.rn.f32 	%f87, %f84, %f80, %f86;
	fma.rn.f32 	%f88, %f84, %f82, %f87;
	mov.f32 	%f89, 0f00000000;
	fma.rn.f32 	%f90, %f89, %f80, %f88;
	add.rn.f32 	%f91, %f85, %f90;
	neg.f32 	%f92, %f91;
	add.rn.f32 	%f93, %f85, %f92;
	add.rn.f32 	%f94, %f93, %f90;
	mov.b32 	%r19, %f91;
	setp.eq.s32 	%p15, %r19, 1118925336;
	add.s32 	%r20, %r19, -1;
	mov.b32 	%f95, %r20;
	mov.u32 	%r21, 922746880;
	mov.b32 	%f96, %r21;
	add.f32 	%f97, %f94, %f96;
	selp.f32 	%f5, %f97, %f94, %p15;
	selp.f32 	%f98, %f95, %f91, %p15;
	mul.f32 	%f99, %f98, 0f3FB8AA3B;
	cvt.rzi.f32.f32 	%f100, %f99;
	mov.f32 	%f101, 0fBF317200;
	fma.rn.f32 	%f102, %f100, %f101, %f98;
	mov.f32 	%f103, 0fB5BFBE8E;
	fma.rn.f32 	%f104, %f100, %f103, %f102;
	mul.f32 	%f105, %f104, 0f3FB8AA3B;
	ex2.approx.f32 	%f106, %f105;
	add.f32 	%f107, %f100, 0f00000000;
	ex2.approx.f32 	%f108, %f107;
	mul.f32 	%f109, %f106, %f108;
	setp.lt.f32 	%p16, %f98, 0fC2D20000;
	selp.f32 	%f110, 0f00000000, %f109, %p16;
	setp.gt.f32 	%p17, %f98, 0f42D20000;
	selp.f32 	%f117, %f2, %f110, %p17;
	setp.eq.f32 	%p18, %f117, %f2;
	@%p18 bra 	BB0_11;

	fma.rn.f32 	%f117, %f117, %f5, %f117;

BB0_11:
	ld.param.f32 	%f116, [_Z7pow_f32ff_param_0];
	setp.eq.f32 	%p19, %f4, 0f3F800000;
	setp.lt.f32 	%p20, %f116, 0f00000000;
	and.pred  	%p21, %p20, %p19;
	mov.b32 	%r22, %f117;
	xor.b32  	%r23, %r22, -2147483648;
	mov.b32 	%f111, %r23;
	selp.f32 	%f121, %f111, %f117, %p21;
	bra.uni 	BB0_25;

BB0_12:
	mov.u32 	%r24, -4194304;
	mov.b32 	%f112, %r24;
	rsqrt.approx.f32 	%f121, %f112;
	bra.uni 	BB0_25;

BB0_13:
	setp.geu.f32 	%p22, %f26, 0f00000000;
	@%p22 bra 	BB0_15;

	rcp.rn.f32 	%f118, %f118;

BB0_15:
	neg.f32 	%f113, %f118;
	mov.b32 	%r25, %f113;
	xor.b32  	%r26, %r25, -2147483648;
	mov.b32 	%f114, %r26;
	setp.eq.f32 	%p23, %f4, 0f3F800000;
	selp.f32 	%f121, %f114, %f113, %p23;
	bra.uni 	BB0_25;

BB0_16:
	setp.eq.f32 	%p24, %f4, 0f3F800000;
	selp.f32 	%f119, %f118, 0f00000000, %p24;
	setp.geu.f32 	%p25, %f26, 0f00000000;
	@%p25 bra 	BB0_18;

	rcp.rn.f32 	%f119, %f119;

BB0_18:
	add.f32 	%f121, %f119, %f119;
	bra.uni 	BB0_25;

BB0_19:
	setp.eq.f32 	%p26, %f118, 0fBF800000;
	mov.f32 	%f121, 0f3F800000;
	@%p26 bra 	BB0_25;

	setp.gt.f32 	%p27, %f1, 0f3F800000;
	selp.f32 	%f120, %f2, 0f00000000, %p27;
	setp.geu.f32 	%p28, %f26, 0f00000000;
	@%p28 bra 	BB0_22;

	rcp.rn.f32 	%f120, %f120;

BB0_22:
	add.f32 	%f121, %f120, %f120;
	bra.uni 	BB0_25;

BB0_23:
	mov.b32 	%r27, %f26;
	setp.lt.s32 	%p29, %r27, 0;
	selp.f32 	%f121, 0f00000000, %f2, %p29;
	bra.uni 	BB0_25;

BB0_24:
	add.f32 	%f121, %f118, %f26;

BB0_25:
	st.param.f32	[func_retval0+0], %f121;
	ret;
}

.visible .func  (.param .b64 func_retval0) _Z7pow_f64dd(
	.param .b64 _Z7pow_f64dd_param_0,
	.param .b64 _Z7pow_f64dd_param_1
)
{
	.reg .pred 	%p<34>;
	.reg .f32 	%f<5>;
	.reg .s32 	%r<39>;
	.reg .s64 	%rd<7>;
	.reg .f64 	%fd<174>;


	ld.param.f64 	%fd30, [_Z7pow_f64dd_param_0];
	ld.param.f64 	%fd31, [_Z7pow_f64dd_param_1];
	setp.eq.f64 	%p1, %fd30, 0d3FF0000000000000;
	mov.f64 	%fd173, 0d3FF0000000000000;
	setp.eq.f64 	%p2, %fd31, 0d0000000000000000;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB1_33;

	abs.f64 	%fd1, %fd30;
	mov.u64 	%rd1, 9218868437227405312;
	mov.b64 	%fd2, %rd1;
	setp.gtu.f64 	%p4, %fd1, %fd2;
	@%p4 bra 	BB1_32;

	abs.f64 	%fd3, %fd31;
	setp.gtu.f64 	%p5, %fd3, %fd2;
	@%p5 bra 	BB1_32;

	setp.eq.f64 	%p6, %fd2, %fd30;
	@%p6 bra 	BB1_31;

	setp.eq.f64 	%p7, %fd3, %fd2;
	@%p7 bra 	BB1_28;

	mul.f64 	%fd33, %fd31, 0d3FE0000000000000;
	cvt.rzi.f64.f64 	%fd34, %fd33;
	fma.rn.f64 	%fd35, %fd34, 0dC000000000000000, %fd31;
	abs.f64 	%fd4, %fd35;
	setp.eq.f64 	%p8, %fd30, 0d0000000000000000;
	@%p8 bra 	BB1_26;

	neg.f64 	%fd36, %fd2;
	setp.eq.f64 	%p9, %fd30, %fd36;
	@%p9 bra 	BB1_22;

	setp.geu.f64 	%p10, %fd30, 0d0000000000000000;
	@%p10 bra 	BB1_9;

	cvt.rzi.f64.f64 	%fd37, %fd31;
	setp.neu.f64 	%p11, %fd37, %fd31;
	@%p11 bra 	BB1_21;

BB1_9:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd1;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r35, %temp}, %fd1;
	}
	shr.u32 	%r17, %r36, 20;
	and.b32  	%r37, %r17, 2047;
	setp.ne.s32 	%p12, %r37, 0;
	@%p12 bra 	BB1_11;

	mul.f64 	%fd38, %fd1, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd38;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r35, %temp}, %fd38;
	}
	shr.u32 	%r18, %r36, 20;
	and.b32  	%r19, %r18, 2047;
	add.s32 	%r37, %r19, -54;

BB1_11:
	add.s32 	%r38, %r37, -1023;
	and.b32  	%r20, %r36, -2146435073;
	or.b32  	%r21, %r20, 1072693248;
	mov.b64 	%fd170, {%r35, %r21};
	setp.lt.u32 	%p13, %r21, 1073127583;
	@%p13 bra 	BB1_13;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd170;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd170;
	}
	add.s32 	%r24, %r23, -1048576;
	mov.b64 	%fd170, {%r22, %r24};
	add.s32 	%r38, %r37, -1022;

BB1_13:
	add.f64 	%fd39, %fd170, 0d3FF0000000000000;
	mov.f64 	%fd41, 0d3FF0000000000000;
	// inline asm
	cvt.rn.f32.f64     %f1,%fd39;
	// inline asm
	// inline asm
	rcp.approx.f32.ftz %f2,%f1;
	// inline asm
	// inline asm
	cvt.f64.f32        %fd40,%f2;
	// inline asm
	neg.f64 	%fd42, %fd39;
	fma.rn.f64 	%fd43, %fd42, %fd40, %fd41;
	fma.rn.f64 	%fd44, %fd43, %fd43, %fd43;
	fma.rn.f64 	%fd45, %fd44, %fd40, %fd40;
	add.f64 	%fd46, %fd170, 0dBFF0000000000000;
	mul.f64 	%fd47, %fd46, %fd45;
	fma.rn.f64 	%fd48, %fd46, %fd45, %fd47;
	mul.f64 	%fd49, %fd48, %fd48;
	mov.f64 	%fd50, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd51, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd52, %fd51, %fd49, %fd50;
	mov.f64 	%fd53, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd54, %fd52, %fd49, %fd53;
	mov.f64 	%fd55, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd56, %fd54, %fd49, %fd55;
	mov.f64 	%fd57, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd58, %fd56, %fd49, %fd57;
	mov.f64 	%fd59, 0d3F6249249242B910;
	fma.rn.f64 	%fd60, %fd58, %fd49, %fd59;
	mov.f64 	%fd61, 0d3F89999999999DFB;
	fma.rn.f64 	%fd62, %fd60, %fd49, %fd61;
	sub.f64 	%fd63, %fd46, %fd48;
	add.f64 	%fd64, %fd63, %fd63;
	neg.f64 	%fd65, %fd48;
	fma.rn.f64 	%fd66, %fd65, %fd46, %fd64;
	mul.f64 	%fd67, %fd45, %fd66;
	mov.f64 	%fd68, 0d3FB5555555555555;
	fma.rn.f64 	%fd69, %fd62, %fd49, 0d3FB5555555555555;
	sub.f64 	%fd70, %fd68, %fd69;
	fma.rn.f64 	%fd71, %fd62, %fd49, %fd70;
	add.f64 	%fd72, %fd71, 0d0000000000000000;
	add.f64 	%fd73, %fd72, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd74, %fd69, %fd73;
	sub.f64 	%fd75, %fd69, %fd74;
	add.f64 	%fd76, %fd75, %fd73;
	mul.rn.f64 	%fd77, %fd74, %fd48;
	neg.f64 	%fd78, %fd77;
	fma.rn.f64 	%fd79, %fd74, %fd48, %fd78;
	fma.rn.f64 	%fd80, %fd74, %fd67, %fd79;
	fma.rn.f64 	%fd81, %fd76, %fd48, %fd80;
	add.f64 	%fd82, %fd77, %fd81;
	sub.f64 	%fd83, %fd77, %fd82;
	add.f64 	%fd84, %fd83, %fd81;
	mul.rn.f64 	%fd85, %fd82, %fd48;
	neg.f64 	%fd86, %fd85;
	fma.rn.f64 	%fd87, %fd82, %fd48, %fd86;
	fma.rn.f64 	%fd88, %fd82, %fd67, %fd87;
	fma.rn.f64 	%fd89, %fd84, %fd48, %fd88;
	add.f64 	%fd90, %fd85, %fd89;
	sub.f64 	%fd91, %fd85, %fd90;
	add.f64 	%fd92, %fd91, %fd89;
	mul.rn.f64 	%fd93, %fd90, %fd48;
	neg.f64 	%fd94, %fd93;
	fma.rn.f64 	%fd95, %fd90, %fd48, %fd94;
	fma.rn.f64 	%fd96, %fd90, %fd67, %fd95;
	fma.rn.f64 	%fd97, %fd92, %fd48, %fd96;
	add.f64 	%fd98, %fd93, %fd97;
	sub.f64 	%fd99, %fd93, %fd98;
	add.f64 	%fd100, %fd99, %fd97;
	add.f64 	%fd101, %fd48, %fd98;
	sub.f64 	%fd102, %fd48, %fd101;
	add.f64 	%fd103, %fd102, %fd98;
	add.f64 	%fd104, %fd103, %fd100;
	fma.rn.f64 	%fd105, %fd45, %fd66, %fd104;
	add.f64 	%fd106, %fd101, %fd105;
	sub.f64 	%fd107, %fd101, %fd106;
	add.f64 	%fd108, %fd107, %fd105;
	cvt.rn.f64.s32 	%fd109, %r38;
	mov.f64 	%fd110, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd111, %fd109, %fd110;
	mov.f64 	%fd112, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd113, %fd109, %fd112;
	add.f64 	%fd114, %fd111, %fd106;
	sub.f64 	%fd115, %fd111, %fd114;
	add.f64 	%fd116, %fd115, %fd106;
	add.f64 	%fd117, %fd116, %fd108;
	add.f64 	%fd118, %fd117, %fd113;
	add.f64 	%fd119, %fd114, %fd118;
	sub.f64 	%fd120, %fd114, %fd119;
	add.f64 	%fd121, %fd120, %fd118;
	mul.f64 	%fd122, %fd31, 0d3F20000000000000;
	setp.gt.f64 	%p14, %fd3, 0d7F0D2A1BE4048F90;
	selp.f64 	%fd123, %fd122, %fd31, %p14;
	mul.rn.f64 	%fd124, %fd119, %fd123;
	neg.f64 	%fd125, %fd124;
	fma.rn.f64 	%fd126, %fd119, %fd123, %fd125;
	fma.rn.f64 	%fd127, %fd121, %fd123, %fd126;
	add.f64 	%fd8, %fd124, %fd127;
	sub.f64 	%fd128, %fd124, %fd8;
	add.f64 	%fd9, %fd128, %fd127;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd8;
	}
	setp.lt.u32 	%p15, %r13, 1082535491;
	setp.lt.s32 	%p16, %r13, -1064875759;
	or.pred  	%p17, %p15, %p16;
	@%p17 bra 	BB1_15;

	setp.lt.s32 	%p18, %r13, 0;
	selp.f64 	%fd129, 0d0000000000000000, %fd2, %p18;
	abs.f64 	%fd130, %fd8;
	setp.gtu.f64 	%p19, %fd130, %fd2;
	add.f64 	%fd131, %fd8, %fd8;
	selp.f64 	%fd171, %fd131, %fd129, %p19;
	bra.uni 	BB1_18;

BB1_15:
	mov.f64 	%fd169, 0d3FF0000000000000;
	mul.f64 	%fd132, %fd8, 0d3FF71547652B82FE;
	cvt.rni.f64.f64 	%fd133, %fd132;
	cvt.rzi.s32.f64 	%r14, %fd133;
	mov.f64 	%fd134, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd135, %fd133, %fd134, %fd8;
	mov.f64 	%fd136, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd137, %fd133, %fd136, %fd135;
	mov.f64 	%fd138, 0d3E928A27E30F5561;
	mov.f64 	%fd139, 0d3E5AE6449C0686C0;
	fma.rn.f64 	%fd140, %fd139, %fd137, %fd138;
	mov.f64 	%fd141, 0d3EC71DE8E6486D6B;
	fma.rn.f64 	%fd142, %fd140, %fd137, %fd141;
	mov.f64 	%fd143, 0d3EFA019A6B2464C5;
	fma.rn.f64 	%fd144, %fd142, %fd137, %fd143;
	mov.f64 	%fd145, 0d3F2A01A0171064A5;
	fma.rn.f64 	%fd146, %fd144, %fd137, %fd145;
	mov.f64 	%fd147, 0d3F56C16C17F29C8D;
	fma.rn.f64 	%fd148, %fd146, %fd137, %fd147;
	mov.f64 	%fd149, 0d3F8111111111A24E;
	fma.rn.f64 	%fd150, %fd148, %fd137, %fd149;
	mov.f64 	%fd151, 0d3FA555555555211D;
	fma.rn.f64 	%fd152, %fd150, %fd137, %fd151;
	mov.f64 	%fd153, 0d3FC5555555555530;
	fma.rn.f64 	%fd154, %fd152, %fd137, %fd153;
	mov.f64 	%fd155, 0d3FE0000000000005;
	fma.rn.f64 	%fd156, %fd154, %fd137, %fd155;
	fma.rn.f64 	%fd158, %fd156, %fd137, %fd169;
	fma.rn.f64 	%fd11, %fd158, %fd137, %fd169;
	shl.b32 	%r15, %r14, 20;
	add.s32 	%r16, %r15, 1072693248;
	abs.s32 	%r25, %r14;
	setp.lt.s32 	%p20, %r25, 1021;
	@%p20 bra 	BB1_17;

	add.s32 	%r26, %r15, 1130364928;
	setp.lt.s32 	%p21, %r14, 0;
	mov.u32 	%r27, 0;
	selp.b32 	%r28, %r26, %r16, %p21;
	shr.s32 	%r29, %r14, 31;
	add.s32 	%r30, %r29, 1073741824;
	and.b32  	%r31, %r30, -57671680;
	add.s32 	%r32, %r28, -1048576;
	mov.b64 	%fd159, {%r27, %r31};
	mul.f64 	%fd160, %fd11, %fd159;
	mov.b64 	%fd161, {%r27, %r32};
	mul.f64 	%fd171, %fd160, %fd161;
	bra.uni 	BB1_18;

BB1_17:
	mov.u32 	%r33, 0;
	mov.b64 	%fd162, {%r33, %r16};
	mul.f64 	%fd171, %fd162, %fd11;

BB1_18:
	abs.f64 	%fd163, %fd171;
	setp.eq.f64 	%p22, %fd163, %fd2;
	@%p22 bra 	BB1_20;

	fma.rn.f64 	%fd171, %fd171, %fd9, %fd171;

BB1_20:
	ld.param.f64 	%fd168, [_Z7pow_f64dd_param_0];
	setp.eq.f64 	%p23, %fd4, 0d3FF0000000000000;
	setp.lt.f64 	%p24, %fd168, 0d0000000000000000;
	and.pred  	%p25, %p24, %p23;
	mov.b64 	%rd2, %fd171;
	xor.b64  	%rd3, %rd2, -9223372036854775808;
	mov.b64 	%fd164, %rd3;
	selp.f64 	%fd173, %fd164, %fd171, %p25;
	bra.uni 	BB1_33;

BB1_21:
	mov.u64 	%rd4, -2251799813685248;
	mov.b64 	%fd173, %rd4;
	bra.uni 	BB1_33;

BB1_22:
	setp.lt.f64 	%p26, %fd31, 0d0000000000000000;
	@%p26 bra 	BB1_24;

	neg.f64 	%fd172, %fd30;
	bra.uni 	BB1_25;

BB1_24:
	mov.f64 	%fd165, 0dBFF0000000000000;
	div.rn.f64 	%fd172, %fd165, %fd30;

BB1_25:
	mov.b64 	%rd5, %fd172;
	xor.b64  	%rd6, %rd5, -9223372036854775808;
	mov.b64 	%fd166, %rd6;
	setp.eq.f64 	%p27, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd173, %fd166, %fd172, %p27;
	bra.uni 	BB1_33;

BB1_26:
	setp.eq.f64 	%p28, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd173, %fd30, 0d0000000000000000, %p28;
	setp.geu.f64 	%p29, %fd31, 0d0000000000000000;
	@%p29 bra 	BB1_33;

	rcp.rn.f64 	%fd173, %fd173;
	bra.uni 	BB1_33;

BB1_28:
	setp.eq.f64 	%p30, %fd30, 0dBFF0000000000000;
	mov.f64 	%fd173, 0d3FF0000000000000;
	@%p30 bra 	BB1_33;

	setp.gt.f64 	%p31, %fd1, 0d3FF0000000000000;
	selp.f64 	%fd173, %fd2, 0d0000000000000000, %p31;
	setp.geu.f64 	%p32, %fd31, 0d0000000000000000;
	@%p32 bra 	BB1_33;

	rcp.rn.f64 	%fd173, %fd173;
	bra.uni 	BB1_33;

BB1_31:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd31;
	}
	setp.lt.s32 	%p33, %r34, 0;
	selp.f64 	%fd173, 0d0000000000000000, %fd2, %p33;
	bra.uni 	BB1_33;

BB1_32:
	add.f64 	%fd173, %fd30, %fd31;

BB1_33:
	st.param.f64	[func_retval0+0], %fd173;
	ret;
}


